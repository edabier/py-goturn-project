{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code tries to fine-tune the model with our dataset. It uses the code provided by **https://github.com/amoudgl/pygoturn**. It is made to be run on Google Colab but you can use it wherever you want.\n"
      ],
      "metadata": {
        "id": "gB0z4SpCmB_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcpK_VaMfL6I",
        "outputId": "ab11dd41-e132-47a1-c44e-ac292d54e795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYqCcn29e7G0",
        "outputId": "d8e9a2fe-f34c-416d-b1af-a58f8571020d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/pygoturn/src\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('./drive/MyDrive/pygoturn/src')\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w1gvdAle7G3"
      },
      "source": [
        "# Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJjWH1Ihe7G3"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V84IT-wwe7G4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ea9a031-ef03-434d-f54e-a3b94faa57ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total dataset size: 1628\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, ConcatDataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "class GOTURN_Dataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Get all image files inside the root folder\n",
        "        self.frame_files = sorted([f for f in os.listdir(root_dir) if f.endswith(\".bmp\")])\n",
        "\n",
        "        # Load bounding boxes\n",
        "        bbox_path = os.path.join(os.path.dirname(root_dir), \"groundtruth_rect.txt\")\n",
        "        if os.path.exists(bbox_path):\n",
        "            self.bboxes = np.loadtxt(bbox_path, delimiter=\",\")\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Bounding box file not found at {bbox_path}\")\n",
        "\n",
        "        # If bbox file contains frame indices, remove first column\n",
        "        if self.bboxes.shape[1] == 5:\n",
        "            self.bboxes = self.bboxes[:, 1:]\n",
        "\n",
        "        # Ensure we have enough frames\n",
        "        if len(self.frame_files) < 2 or len(self.bboxes) < 2:\n",
        "            raise ValueError(\"Not enough frames or bounding boxes in the dataset\")\n",
        "\n",
        "        # Store image pairs and corresponding bounding boxes\n",
        "        self.data = self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\"\n",
        "        Loads image pairs and bounding boxes for each frame sequence.\n",
        "        \"\"\"\n",
        "        data = []\n",
        "        for i in range(len(self.frame_files) - 1):\n",
        "            prev_frame_path = os.path.join(self.root_dir, self.frame_files[i])\n",
        "            curr_frame_path = os.path.join(self.root_dir, self.frame_files[i + 1])\n",
        "            bbox = self.bboxes[i + 1]  # Assign bbox of next frame\n",
        "\n",
        "            data.append((prev_frame_path, curr_frame_path, bbox))\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        prev_frame_path, curr_frame_path, bbox = self.data[idx]\n",
        "\n",
        "        # Read images using OpenCV\n",
        "        prev_frame = cv2.imread(prev_frame_path)\n",
        "        curr_frame = cv2.imread(curr_frame_path)\n",
        "\n",
        "        # Ensure the images are read correctly\n",
        "        if prev_frame is None or curr_frame is None:\n",
        "            raise ValueError(f\"Error loading image: {prev_frame_path}, {curr_frame_path}\")\n",
        "\n",
        "        # Convert from BGR (OpenCV default) to RGB\n",
        "        prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2RGB)\n",
        "        curr_frame = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Convert numpy array to PIL Image\n",
        "        prev_frame = Image.fromarray(prev_frame)\n",
        "        curr_frame = Image.fromarray(curr_frame)\n",
        "\n",
        "        # Apply the transformation if any\n",
        "        if self.transform:\n",
        "            # Ensure same random transformation is applied to both frames\n",
        "            seed = random.randint(0, 99999)  # Generate a random seed\n",
        "            torch.manual_seed(seed)  # Set the seed for PyTorch transforms\n",
        "            prev_frame = self.transform(prev_frame)\n",
        "            torch.manual_seed(seed)  # Reset the seed to ensure same transform\n",
        "            curr_frame = self.transform(curr_frame)\n",
        "\n",
        "        return prev_frame, curr_frame, torch.tensor(bbox, dtype=torch.float32)\n",
        "\n",
        "\n",
        "# Define multiple transformation variations\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize((227, 360)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "augmentations = [\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((227, 360)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((227, 360)),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((227, 360)),\n",
        "        transforms.RandomResizedCrop((227, 360), scale=(0.8, 1.0)),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "]\n",
        "\n",
        "# Create datasets with different transformations\n",
        "datasets = []\n",
        "sequences = [\"swan\", \"bag\", \"bear\", \"rhino\", \"book\"]\n",
        "\n",
        "for seq in sequences:\n",
        "    datasets.append(GOTURN_Dataset(f\"../data/OTB/{seq}/img\", transform=base_transform))  # Base dataset\n",
        "    for aug in augmentations:\n",
        "        datasets.append(GOTURN_Dataset(f\"../data/OTB/{seq}/img\", transform=aug))  # Augmented datasets\n",
        "\n",
        "# Concatenate the datasets\n",
        "combined_dataset = ConcatDataset(datasets)\n",
        "\n",
        "print(f\"Total dataset size: {len(combined_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fav992gve7G4"
      },
      "source": [
        "## Fine Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install got10k #if needed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31cvD40xhZ--",
        "outputId": "58f01e64-6455-48a4-92df-b8f11c7f66d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting got10k\n",
            "  Downloading got10k-0.1.3.tar.gz (31 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from got10k) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from got10k) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from got10k) (11.1.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from got10k) (2.0.7)\n",
            "Collecting fire (from got10k)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wget (from got10k)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->got10k) (2.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->got10k) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->got10k) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->got10k) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->got10k) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->got10k) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->got10k) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->got10k) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->got10k) (1.17.0)\n",
            "Building wheels for collected packages: got10k, fire, wget\n",
            "  Building wheel for got10k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for got10k: filename=got10k-0.1.3-py3-none-any.whl size=43858 sha256=693a3775a81c69b212a0ca891bd91508b3c1a1cdd1a26f73150c2e75d191fe10\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/75/da/81b64122700ec083d162c374aba1922beb523d542c429ed8ca\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=4ed7b1828f8495717a4d11a8306dfd5002fdef95282e77bb0a6df50c52848881\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=dbdfed534f62856cd9d554603b298a5490575ab8b9c4c5fcce9124ad5e99c5df\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built got10k fire wget\n",
            "Installing collected packages: wget, fire, got10k\n",
            "Successfully installed fire-0.7.0 got10k-0.1.3 wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld_Ct8Q6e7G4",
        "outputId": "5da61cc2-22f8-4903-c844-1302b66df25e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:02<00:00, 84.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/300, Step 0/7, Loss: 110.74299621582031\n",
            "Epoch 1/300, Step 0/7, Loss: 86.9543685913086\n",
            "Epoch 2/300, Step 0/7, Loss: 51.60289764404297\n",
            "Epoch 3/300, Step 0/7, Loss: 43.509971618652344\n",
            "Epoch 4/300, Step 0/7, Loss: 45.34307098388672\n",
            "Epoch 5/300, Step 0/7, Loss: 41.39385986328125\n",
            "Epoch 6/300, Step 0/7, Loss: 40.110633850097656\n",
            "Epoch 7/300, Step 0/7, Loss: 40.62428283691406\n",
            "Epoch 8/300, Step 0/7, Loss: 39.310997009277344\n",
            "Epoch 9/300, Step 0/7, Loss: 37.426395416259766\n",
            "Epoch 10/300, Step 0/7, Loss: 34.927513122558594\n",
            "Epoch 11/300, Step 0/7, Loss: 26.967416763305664\n",
            "Epoch 12/300, Step 0/7, Loss: 22.292936325073242\n",
            "Epoch 13/300, Step 0/7, Loss: 17.704883575439453\n",
            "Epoch 14/300, Step 0/7, Loss: 15.726051330566406\n",
            "Epoch 15/300, Step 0/7, Loss: 14.655476570129395\n",
            "Epoch 16/300, Step 0/7, Loss: 14.180479049682617\n",
            "Epoch 17/300, Step 0/7, Loss: 13.946524620056152\n",
            "Epoch 18/300, Step 0/7, Loss: 13.535764694213867\n",
            "Epoch 19/300, Step 0/7, Loss: 12.867097854614258\n",
            "Epoch 20/300, Step 0/7, Loss: 12.735795974731445\n",
            "Epoch 21/300, Step 0/7, Loss: 11.688606262207031\n",
            "Epoch 22/300, Step 0/7, Loss: 11.481870651245117\n",
            "Epoch 23/300, Step 0/7, Loss: 11.193843841552734\n",
            "Epoch 24/300, Step 0/7, Loss: 10.726701736450195\n",
            "Epoch 25/300, Step 0/7, Loss: 11.097371101379395\n",
            "Epoch 26/300, Step 0/7, Loss: 10.507747650146484\n",
            "Epoch 27/300, Step 0/7, Loss: 9.791070938110352\n",
            "Epoch 28/300, Step 0/7, Loss: 9.63268756866455\n",
            "Epoch 29/300, Step 0/7, Loss: 9.346118927001953\n",
            "Epoch 30/300, Step 0/7, Loss: 9.131584167480469\n",
            "Epoch 31/300, Step 0/7, Loss: 8.111141204833984\n",
            "Epoch 32/300, Step 0/7, Loss: 8.242854118347168\n",
            "Epoch 33/300, Step 0/7, Loss: 7.761135578155518\n",
            "Epoch 34/300, Step 0/7, Loss: 7.770140171051025\n",
            "Epoch 35/300, Step 0/7, Loss: 7.981182098388672\n",
            "Epoch 36/300, Step 0/7, Loss: 7.614580154418945\n",
            "Epoch 37/300, Step 0/7, Loss: 7.70292854309082\n",
            "Epoch 38/300, Step 0/7, Loss: 7.968569755554199\n",
            "Epoch 39/300, Step 0/7, Loss: 7.317135810852051\n",
            "Epoch 40/300, Step 0/7, Loss: 8.016828536987305\n",
            "Epoch 41/300, Step 0/7, Loss: 7.141977310180664\n",
            "Epoch 42/300, Step 0/7, Loss: 7.493112564086914\n",
            "Epoch 43/300, Step 0/7, Loss: 7.615752696990967\n",
            "Epoch 44/300, Step 0/7, Loss: 7.222510814666748\n",
            "Epoch 45/300, Step 0/7, Loss: 7.492517471313477\n",
            "Epoch 46/300, Step 0/7, Loss: 6.712003231048584\n",
            "Epoch 47/300, Step 0/7, Loss: 7.036125659942627\n",
            "Epoch 48/300, Step 0/7, Loss: 6.648251533508301\n",
            "Epoch 49/300, Step 0/7, Loss: 7.344127655029297\n",
            "Epoch 50/300, Step 0/7, Loss: 7.045448303222656\n",
            "Epoch 51/300, Step 0/7, Loss: 6.686849594116211\n",
            "Epoch 52/300, Step 0/7, Loss: 6.364355564117432\n",
            "Epoch 53/300, Step 0/7, Loss: 6.505268096923828\n",
            "Epoch 54/300, Step 0/7, Loss: 6.1325764656066895\n",
            "Epoch 55/300, Step 0/7, Loss: 7.009152412414551\n",
            "Epoch 56/300, Step 0/7, Loss: 6.247162342071533\n",
            "Epoch 57/300, Step 0/7, Loss: 6.224615097045898\n",
            "Epoch 58/300, Step 0/7, Loss: 5.785449981689453\n",
            "Epoch 59/300, Step 0/7, Loss: 6.339069366455078\n",
            "Epoch 60/300, Step 0/7, Loss: 6.265988349914551\n",
            "Epoch 61/300, Step 0/7, Loss: 5.69124698638916\n",
            "Epoch 62/300, Step 0/7, Loss: 5.817094802856445\n",
            "Epoch 63/300, Step 0/7, Loss: 5.911910533905029\n",
            "Epoch 64/300, Step 0/7, Loss: 5.465235233306885\n",
            "Epoch 65/300, Step 0/7, Loss: 5.741140365600586\n",
            "Epoch 66/300, Step 0/7, Loss: 5.896961212158203\n",
            "Epoch 67/300, Step 0/7, Loss: 5.7554473876953125\n",
            "Epoch 68/300, Step 0/7, Loss: 6.04867696762085\n",
            "Epoch 69/300, Step 0/7, Loss: 5.9338507652282715\n",
            "Epoch 70/300, Step 0/7, Loss: 5.699986934661865\n",
            "Epoch 71/300, Step 0/7, Loss: 6.255360126495361\n",
            "Epoch 72/300, Step 0/7, Loss: 5.809140682220459\n",
            "Epoch 73/300, Step 0/7, Loss: 5.824957847595215\n",
            "Epoch 74/300, Step 0/7, Loss: 5.5962395668029785\n",
            "Epoch 75/300, Step 0/7, Loss: 5.834249496459961\n",
            "Epoch 76/300, Step 0/7, Loss: 5.533575057983398\n",
            "Epoch 77/300, Step 0/7, Loss: 5.8510541915893555\n",
            "Epoch 78/300, Step 0/7, Loss: 5.539968013763428\n",
            "Epoch 79/300, Step 0/7, Loss: 5.583470344543457\n",
            "Epoch 80/300, Step 0/7, Loss: 5.927563667297363\n",
            "Epoch 81/300, Step 0/7, Loss: 5.896760940551758\n",
            "Epoch 82/300, Step 0/7, Loss: 6.003179550170898\n",
            "Epoch 83/300, Step 0/7, Loss: 6.019757270812988\n",
            "Epoch 84/300, Step 0/7, Loss: 5.601590156555176\n",
            "Epoch 85/300, Step 0/7, Loss: 5.3129658699035645\n",
            "Epoch 86/300, Step 0/7, Loss: 5.333047866821289\n",
            "Epoch 87/300, Step 0/7, Loss: 5.370950698852539\n",
            "Epoch 88/300, Step 0/7, Loss: 5.785457611083984\n",
            "Epoch 89/300, Step 0/7, Loss: 5.635960578918457\n",
            "Epoch 90/300, Step 0/7, Loss: 5.4480366706848145\n",
            "Epoch 91/300, Step 0/7, Loss: 5.337975025177002\n",
            "Epoch 92/300, Step 0/7, Loss: 5.428877353668213\n",
            "Epoch 93/300, Step 0/7, Loss: 5.134969711303711\n",
            "Epoch 94/300, Step 0/7, Loss: 5.166777610778809\n",
            "Epoch 95/300, Step 0/7, Loss: 5.638054370880127\n",
            "Epoch 96/300, Step 0/7, Loss: 5.503726005554199\n",
            "Epoch 97/300, Step 0/7, Loss: 5.077564239501953\n",
            "Epoch 98/300, Step 0/7, Loss: 5.42625617980957\n",
            "Epoch 99/300, Step 0/7, Loss: 5.595256805419922\n",
            "Epoch 100/300, Step 0/7, Loss: 5.462414741516113\n",
            "Epoch 101/300, Step 0/7, Loss: 5.324831962585449\n",
            "Epoch 102/300, Step 0/7, Loss: 5.309327602386475\n",
            "Epoch 103/300, Step 0/7, Loss: 5.423192501068115\n",
            "Epoch 104/300, Step 0/7, Loss: 5.378946781158447\n",
            "Epoch 105/300, Step 0/7, Loss: 5.178269386291504\n",
            "Epoch 106/300, Step 0/7, Loss: 5.2688093185424805\n",
            "Epoch 107/300, Step 0/7, Loss: 5.256293773651123\n",
            "Epoch 108/300, Step 0/7, Loss: 5.315323829650879\n",
            "Epoch 109/300, Step 0/7, Loss: 5.446650505065918\n",
            "Epoch 110/300, Step 0/7, Loss: 5.11156702041626\n",
            "Epoch 111/300, Step 0/7, Loss: 5.647856712341309\n",
            "Epoch 112/300, Step 0/7, Loss: 5.071002006530762\n",
            "Epoch 113/300, Step 0/7, Loss: 5.296607971191406\n",
            "Epoch 114/300, Step 0/7, Loss: 5.390467643737793\n",
            "Epoch 115/300, Step 0/7, Loss: 5.525424480438232\n",
            "Epoch 116/300, Step 0/7, Loss: 5.15644645690918\n",
            "Epoch 117/300, Step 0/7, Loss: 5.150017261505127\n",
            "Epoch 118/300, Step 0/7, Loss: 5.060052871704102\n",
            "Epoch 119/300, Step 0/7, Loss: 5.3006391525268555\n",
            "Epoch 120/300, Step 0/7, Loss: 4.977118015289307\n",
            "Epoch 121/300, Step 0/7, Loss: 4.997917175292969\n",
            "Epoch 122/300, Step 0/7, Loss: 4.908100128173828\n",
            "Epoch 123/300, Step 0/7, Loss: 4.928503036499023\n",
            "Epoch 124/300, Step 0/7, Loss: 4.984846115112305\n",
            "Epoch 125/300, Step 0/7, Loss: 5.111629486083984\n",
            "Epoch 126/300, Step 0/7, Loss: 4.605062961578369\n",
            "Epoch 127/300, Step 0/7, Loss: 5.012788772583008\n",
            "Epoch 128/300, Step 0/7, Loss: 5.384632110595703\n",
            "Epoch 129/300, Step 0/7, Loss: 5.140127182006836\n",
            "Epoch 130/300, Step 0/7, Loss: 4.5809502601623535\n",
            "Epoch 131/300, Step 0/7, Loss: 4.968766212463379\n",
            "Epoch 132/300, Step 0/7, Loss: 4.741262435913086\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from goturn import TrackerGOTURN\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create dataset instance\n",
        "# dataset = GOTURN_Dataset(\"../data/OTB/swan/img\", transform=None)\n",
        "\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(combined_dataset, batch_size=256, shuffle=True, num_workers=0)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_epochs = 50\n",
        "\n",
        "# Assuming you've already set up the TrackerGOTURN class\n",
        "tracker = TrackerGOTURN(net_path=\"./pytorch_goturn.pth\")\n",
        "\n",
        "# Set model to training mode\n",
        "tracker.net.train()\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = optim.Adam(tracker.net.parameters(), lr=1e-4)  # You can adjust the learning rate\n",
        "criterion = torch.nn.SmoothL1Loss()\n",
        "\n",
        "# Example training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (prev_frame, curr_frame, bbox) in enumerate(train_loader):\n",
        "        prev_frame, curr_frame, bbox = prev_frame.to(device), curr_frame.to(device), bbox.to(device)\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        pred_bbox = tracker.net(prev_frame, curr_frame)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(pred_bbox, bbox)\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 10 == 0:  # Print every 10 steps\n",
        "            print(f'Epoch {epoch}/{num_epochs}, Step {i}/{len(train_loader)}, Loss: {loss.item()}')\n",
        "\n",
        "# Save the fine-tuned model\n",
        "torch.save(tracker.net.state_dict(), \"fine_tuned_goturn.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the new weights"
      ],
      "metadata": {
        "id": "jhDEChegmffI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivFHG8UXe7G4"
      },
      "outputs": [],
      "source": [
        "# Load the fine-tuned checkpoint\n",
        "checkpoint = torch.load('./fine_tuned_goturn.pth', map_location=torch.device('cuda'))\n",
        "\n",
        "# Create a new dictionary to mimic the original model's structure\n",
        "new_checkpoint = {\n",
        "    'state_dict': checkpoint\n",
        "}\n",
        "\n",
        "# Save the new checkpoint\n",
        "torch.save(new_checkpoint, './fine_tuned_goturn_reformatted.pth')\n",
        "\n",
        "# Check the keys in the new checkpoint to ensure it's in the right format\n",
        "new_checkpoint = torch.load('./fine_tuned_goturn_reformatted.pth', map_location=torch.device('cuda'))\n",
        "print(new_checkpoint.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ-BhsJoe7G5"
      },
      "source": [
        "You can run the test by changing the weights on the main notebook (*Project_test.ipynb*) in our github. (the results aren't great)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}